{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\APP\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from mxnet.gluon import nn\n",
    "\n",
    "net = nn.Sequential()\n",
    "with net.name_scope():\n",
    "    net.add(\n",
    "        # 第一阶段\n",
    "        nn.Conv2D(channels=96, kernel_size=11,\n",
    "                 strides=4, activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=3, strides=2),\n",
    "        # 第二阶段\n",
    "        nn.Conv2D(channels=256, kernel_size=5,\n",
    "                 padding=2, activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=3, strides=2),\n",
    "        # 第三阶段\n",
    "        nn.Conv2D(channels=384, kernel_size=3,\n",
    "                 padding=1, activation='relu'),\n",
    "        nn.Conv2D(channels=384, kernel_size=3,\n",
    "                 padding=1, activation='relu'),\n",
    "        nn.Conv2D(channels=384, kernel_size=3,\n",
    "                 padding=1, activation='relu'),\n",
    "        nn.MaxPool2D(pool_size=2, strides=2),\n",
    "        # 第四阶段\n",
    "        nn.Flatten(),\n",
    "        nn.Dense(4096, activation='relu'),\n",
    "        nn.Dropout(0.5),\n",
    "        # 第五阶段\n",
    "        nn.Dense(4096, activation='relu'),\n",
    "        nn.Dropout(0.5),\n",
    "        # 第六阶段\n",
    "        nn.Dense(10),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据\n",
    "依旧使用前面的 FashionMNIST 数据进行训练,在训练之前首先 resize 到224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\APP\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\mxnet\\gluon\\data\\vision.py:126: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  label = np.fromstring(fin.read(), dtype=np.uint8).astype(np.int32)\n",
      "E:\\APP\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\mxnet\\gluon\\data\\vision.py:130: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "  data = np.fromstring(fin.read(), dtype=np.uint8)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import utils\n",
    "\n",
    "train_data, test_data = utils.load_data_fashion_mnist(\n",
    "    batch_size=64, resize=224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练\n",
    "这时候我们可以开始训练。相对于前面的 LeNet，我们做了一下三个改动：\n",
    "1. 使用 Xavier 来初始化参数\n",
    "2. 使用了更小的学习率\n",
    "3. 默认只迭代一轮（时间考虑）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import init\n",
    "from mxnet import gluon\n",
    "\n",
    "ctx = utils.try_gpu()\n",
    "net.initialize(ctx=ctx, init=init.Xavier())\n",
    "\n",
    "loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "trainer = gluon.Trainer(net.collect_params(),\n",
    "                       'sgd',\n",
    "                       {'learning_rate':0.01})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "def _get_batch(batch, ctx):\n",
    "    \"\"\"return data and label on ctx\"\"\"\n",
    "    if isinstance(batch, mx.io.DataBatch):\n",
    "        data = batch.data[0]\n",
    "        label = batch.label[0]\n",
    "    else:\n",
    "        data, label = batch\n",
    "    return (gluon.utils.split_and_load(data, ctx),\n",
    "           gluon.utils.split_and_load(label, ctx),\n",
    "           data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from mxnet import autograd\n",
    "def train(train_data, test_data, net, loss, trainer, ctx, num_epochs, print_batches=None):\n",
    "    \"\"\"Train a network\"\"\"\n",
    "    print(\"Start training on \", ctx)\n",
    "    if isinstance(ctx, mx.Context):\n",
    "        ctx = [ctx]\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_acc, n, m = 0.0, 0.0, 0.0, 0.0\n",
    "        if isinstance(train_data, mx.io.MXDataIter):\n",
    "            train_data.reset()\n",
    "        start = time()\n",
    "        for i, batch in enumerate(train_data):\n",
    "            data, label, batch_size = _get_batch(batch, ctx)\n",
    "            losses = []\n",
    "            with autograd.record():\n",
    "                outputs = [net(X) for X in data]\n",
    "                losses = [loss(yhat, y) for yhat, y in zip(outputs, label)]\n",
    "            for l in losses:\n",
    "                l.backward()\n",
    "            train_acc += sum([(yhat.argmax(axis=1)==y).sum().asscalar()\n",
    "                              for yhat, y in zip(outputs, label)])\n",
    "            train_loss += sum([l.sum().asscalar() for l in losses])\n",
    "            trainer.step(batch_size)\n",
    "            n += batch_size\n",
    "            m += sum([y.size for y in label])\n",
    "            if print_batches and (i+1) % print_batches == 0:\n",
    "                print(\"Batch %d. Loss: %f, Train acc %f\" % (\n",
    "                    n, train_loss/n, train_acc/m\n",
    "                ))\n",
    "\n",
    "        test_acc = evaluate_accuracy(test_data, net, ctx)\n",
    "        print(\"Epoch %d. Loss: %.3f, Train acc %.2f, Test acc %.2f, Time %.1f sec\" % (\n",
    "            epoch, train_loss/n, train_acc/m, test_acc, time() - start\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training on  gpu(0)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-77e07efafec0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m train(train_data, test_data, net, loss, \n\u001b[1;32m----> 2\u001b[1;33m      trainer,ctx, num_epochs=1)\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-17072561cadf>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_data, test_data, net, loss, trainer, ctx, num_epochs, print_batches)\u001b[0m\n\u001b[0;32m     30\u001b[0m                 ))\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m         print(\"Epoch %d. Loss: %.3f, Train acc %.2f, Test acc %.2f, Time %.1f sec\" % (\n\u001b[0;32m     34\u001b[0m             \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'evaluate_accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "train(train_data, test_data, net, loss, \n",
    "     trainer,ctx, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
