{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 初始化模型参数\n",
    "仍然使用 MLP 这个例子来详细解释如何初始化模型参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\APP\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from mxnet.gluon import nn\n",
    "from mxnet import nd\n",
    "\n",
    "def get_net():\n",
    "    net = nn.Sequential()\n",
    "    with net.name_scope():\n",
    "        net.add(\n",
    "            nn.Dense(units=10, activation='relu')\n",
    "        )\n",
    "    return net\n",
    "\n",
    "x = nd.random_uniform(shape=(3,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter sequential0_dense0_weight has not been initialized. Note that you should initialize parameters and create Trainer with Block.collect_params() instead of Block.params because the later does not include Parameters of nested child Blocks"
     ]
    }
   ],
   "source": [
    "# 如果不进行初始化直接跑 forward，则系统会报错，因为没有进行初始化。\n",
    "import sys\n",
    "try:\n",
    "    net = get_net()\n",
    "    net(x)\n",
    "except RuntimeError as err:\n",
    "    sys.stderr.write(str(err))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\APP\\Anaconda3\\envs\\tensorflow1\\lib\\site-packages\\mxnet\\gluon\\parameter.py:320: UserWarning: Parameter sequential0_dense0_bias is already initialized, ignoring. Set force_reinit=True to re-initialize.\n  \"Set force_reinit=True to re-initialize.\"%self.name)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n[[0.         0.05347166 0.10563602 0.         0.         0.03620155\n  0.10653425 0.04017445 0.         0.        ]\n [0.         0.04869549 0.06332826 0.         0.         0.06620608\n  0.06004141 0.01575539 0.         0.        ]\n [0.         0.04273751 0.0169073  0.02372442 0.         0.07875059\n  0.02189449 0.01091669 0.         0.        ]]\n<NDArray 3x10 @cpu(0)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 应当像如下方式进行使用\n",
    "net.initialize()\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 访问模型参数\n",
    "之前我们提到过可以通过 weight 和 bias 访问 Dense 的参数，他们是 Parameter 这个类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n[[ 0.01847461 -0.03004881 -0.02461551 -0.01465906 -0.05932271]\n [-0.0595007   0.0434817   0.04195441  0.05774786  0.00482907]\n [ 0.04922146  0.0243923  -0.06268584  0.04367422  0.03679534]\n [-0.06364554  0.03010933  0.05611894 -0.02152951  0.03825361]\n [-0.04667019  0.0062413   0.02105976 -0.00708959 -0.01553655]\n [ 0.01372761  0.0453613   0.06544485 -0.0313003   0.01013632]\n [ 0.03303149  0.0550149  -0.0692654   0.02017318  0.06154171]\n [-0.03021475  0.0246454  -0.00283234  0.02891331  0.04083297]\n [-0.04714675 -0.06862465  0.01053514 -0.02463352  0.05170998]\n [ 0.01649272  0.000875   -0.00304539 -0.06312138  0.00185619]]\n<NDArray 10x5 @cpu(0)> \n[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n<NDArray 10 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "w = net[0].weight\n",
    "b = net[0].bias\n",
    "print(w.data(),b.data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用不同的初始函数来进行初始化\n",
    "使用默认的初始化函数进行初始化权重会将所有的权重初始化在 [-0.07, 0.07] 之间均匀分布的随机数。我们也同样可以使用别的初始化方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n<NDArray 10 @cpu(0)>\n\n[[ 0.01847461 -0.03004881 -0.02461551 -0.01465906 -0.05932271]\n [-0.0595007   0.0434817   0.04195441  0.05774786  0.00482907]\n [ 0.04922146  0.0243923  -0.06268584  0.04367422  0.03679534]\n [-0.06364554  0.03010933  0.05611894 -0.02152951  0.03825361]\n [-0.04667019  0.0062413   0.02105976 -0.00708959 -0.01553655]\n [ 0.01372761  0.0453613   0.06544485 -0.0313003   0.01013632]\n [ 0.03303149  0.0550149  -0.0692654   0.02017318  0.06154171]\n [-0.03021475  0.0246454  -0.00283234  0.02891331  0.04083297]\n [-0.04714675 -0.06862465  0.01053514 -0.02463352  0.05170998]\n [ 0.01649272  0.000875   -0.00304539 -0.06312138  0.00185619]]\n<NDArray 10x5 @cpu(0)>\n\n[[ 0.0170481   0.01593742  0.00953097  0.01237212  0.01100659]\n [ 0.0149727  -0.04226414 -0.00451335  0.00651215 -0.01914961]\n [ 0.01555002 -0.01896955  0.01123714 -0.02291898 -0.00462218]\n [ 0.0240115   0.00868043 -0.00074824 -0.02312076 -0.00058032]\n [-0.00211779  0.00731891  0.0027211   0.01233792 -0.04634582]\n [ 0.01406007 -0.00139362  0.01100711  0.0079067   0.01766869]\n [-0.00078459  0.00135625 -0.01278795  0.00955986  0.02593908]\n [-0.01148726  0.0156632  -0.02068213  0.02071551 -0.01458842]\n [ 0.03683861 -0.00313866 -0.00164353  0.02394312 -0.00075109]\n [ 0.00535897  0.00705025  0.01629573 -0.01302398 -0.00335013]]\n<NDArray 10x5 @cpu(0)> \n[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n<NDArray 10 @cpu(0)>\n\n[[1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1.]\n [1. 1. 1. 1. 1.]]\n<NDArray 10x5 @cpu(0)> \n[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n<NDArray 10 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "# 使用均值为0，方差为 0.02 的正态分布\n",
    "from mxnet import init\n",
    "\n",
    "params = net.collect_params()\n",
    "# print(params)\n",
    "print(params['sequential0_dense0_bias'].data())\n",
    "print(params.get('dense0_weight').data())\n",
    "\n",
    "params.initialize(init=init.Normal(sigma=0.02), \n",
    "                  force_reinit=True)\n",
    "print(net[0].weight.data(), net[0].bias.data())\n",
    "\n",
    "# 使用全1 进行初始化\n",
    "params.initialize(init=init.One(), \n",
    "                  force_reinit=True)\n",
    "print(net[0].weight.data(), net[0].bias.data())\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 共享模型参数\n",
    "有时候我们想在层之间共享同一份参数，我们可以通过 Block 的 params 输出参数来手动置顶参数，而不是让系统自动生成。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n[[ 0.02227607  0.06482667 -0.00704898 -0.05877154]\n [-0.01320309 -0.00964738  0.03057034  0.06518946]\n [ 0.04743372 -0.00585949  0.03721602 -0.00719421]\n [ 0.05950423  0.03667859 -0.0231606   0.06820413]]\n<NDArray 4x4 @cpu(0)>\n\n[[ 0.02227607  0.06482667 -0.00704898 -0.05877154]\n [-0.01320309 -0.00964738  0.03057034  0.06518946]\n [ 0.04743372 -0.00585949  0.03721602 -0.00719421]\n [ 0.05950423  0.03667859 -0.0231606   0.06820413]]\n<NDArray 4x4 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "net = nn.Sequential()\n",
    "with net.name_scope():\n",
    "    net.add(nn.Dense(4, activation=\"relu\"))\n",
    "    net.add(nn.Dense(4, activation=\"relu\"))\n",
    "    net.add(nn.Dense(4, activation=\"relu\", \n",
    "                     params=net[-1].params))\n",
    "    net.add(nn.Dense(2))\n",
    "    \n",
    "net.initialize()\n",
    "net(x)\n",
    "print(net[1].weight.data())\n",
    "print(net[2].weight.data())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自定义初始化方法\n",
    "下面自定义一个初始化方法，通过重载 _init_weight 来实现不同的初始化方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyInit(init.Initializer):\n",
    "    def __init__(self):\n",
    "        super(MyInit, self).__init__()\n",
    "        self.set_verbose = True\n",
    "    def _init_weight(self, _, arr):\n",
    "        # 初始化权重，使用out=arr后我们不需要指定形状\n",
    "        print('init weight', arr.shape)\n",
    "        nd.random_uniform(low=5,high=10, out=arr)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
